{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1005f9b7",
   "metadata": {},
   "source": [
    "**PART 1: Data Extraction and Feature Extraction with Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe635cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (25.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa==0.11.0 in c:\\python312\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numba==0.61.2 in c:\\python312\\lib\\site-packages (0.61.2)\n",
      "Requirement already satisfied: llvmlite in c:\\python312\\lib\\site-packages (0.44.0)\n",
      "Requirement already satisfied: soxr in c:\\python312\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: soundfile in c:\\python312\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\python312\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (2.3.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (1.8.2)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from librosa==0.11.0) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from librosa==0.11.0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\python312\\lib\\site-packages (from librosa==0.11.0) (1.1.1)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: future in c:\\python312\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa==0.11.0) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa==0.11.0) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa==0.11.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa==0.11.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa==0.11.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa==0.11.0) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.1.0->librosa==0.11.0) (3.4.0)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.3\n",
      "    Uninstalling numpy-2.3.3:\n",
      "      Successfully uninstalled numpy-2.3.3\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.1 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.2.6 which is incompatible.\n",
      "torchvision 0.19.1+cu121 requires torch==2.4.1+cu121, but you have torch 2.8.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (2.2.6)\n",
      "Requirement already satisfied: librosa in c:\\python312\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (4.67.1)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\python312\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: soundfile in c:\\python312\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\python312\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\python312\\lib\\site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\python312\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\python312\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\python312\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\python312\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\python312\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\python312\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: torch==2.8.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torchaudio) (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (3.15.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.8.0->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.8.0->torchaudio) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: future in c:\\python312\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\python312\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python312\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy>=1.13.3->torch==2.8.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch==2.8.0->torchaudio) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
      "Requirement already satisfied: imageio-ffmpeg in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (0.6.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: soundfile in c:\\python312\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (2.2.6)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (4.67.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\python312\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from moviepy) (1.1.1)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in c:\\python312\\lib\\site-packages (from moviepy) (10.3.0)\n",
      "Requirement already satisfied: torch==2.8.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torchaudio) (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.8.0->torchaudio) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.8.0->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch==2.8.0->torchaudio) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.8.0->torchaudio) (80.9.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cyborg 15\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy>=1.13.3->torch==2.8.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch==2.8.0->torchaudio) (2.1.5)\n",
      "Using cached numpy-2.3.3-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-2.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~-p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~=p (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~~p (c:\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.1 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.3.3 which is incompatible.\n",
      "torchvision 0.19.1+cu121 requires torch==2.4.1+cu121, but you have torch 2.8.0 which is incompatible.\n",
      "numba 0.61.2 requires numpy<2.3,>=1.24, but you have numpy 2.3.3 which is incompatible.\n",
      "scipy 1.13.0 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. Pre - Requisite\n",
    "Install all Library\n",
    "'''\n",
    "# 1) Upgrade core tooling inside THIS kernel\n",
    "%pip install --upgrade pip setuptools wheel --user\n",
    "\n",
    "# 2) Clean install of audio deps (librosa works with Py3.12 now via numba>=0.61)\n",
    "%pip install librosa==0.11.0 numba==0.61.2 llvmlite soxr soundfile ffmpeg-python matplotlib tqdm pandas numpy --user\n",
    "\n",
    "%pip install pandas numpy librosa torchaudio tqdm ffmpeg-python matplotlib soundfile --user\n",
    "%pip install --upgrade moviepy imageio-ffmpeg torchaudio soundfile numpy tqdm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201c97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, random, subprocess, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio, display\n",
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ae60db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SN_ROOT: C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\n",
      "WORK_DIR: C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\sn_audio_work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORG 15\\AppData\\Local\\Temp\\ipykernel_3516\\959740583.py:17: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.set_audio_backend(\"soundfile\")  # stable on Windows\n",
      "C:\\Users\\CYBORG 15\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchaudio\\_internal\\module_utils.py:71: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "SN_ROOT = Path(r\"C:/Users/CYBORG 15/Documents/GitHub/elec5305-project-520038655/SoccerNet\")\n",
    "SN_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SOCCERNET_NDA = 's0cc3rn3t'\n",
    "\n",
    "# Workspace\n",
    "WORK_DIR  = Path(\"./sn_audio_work\"); WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUDIO_DIR = WORK_DIR / \"full_match_audio_wav\"; AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLIPS_DIR = WORK_DIR / \"clips\";               CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FEAT_DIR  = WORK_DIR / \"mel64\";               FEAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Audio + reproducibility\n",
    "TARGET_SR    = 16000\n",
    "WINDOWS      = [15, 30]   # 15s/30s event windows\n",
    "RANDOM_SEED  = 1337\n",
    "random.seed(RANDOM_SEED)\n",
    "torchaudio.set_audio_backend(\"soundfile\")  # stable on Windows\n",
    "\n",
    "print(\"SN_ROOT:\", SN_ROOT)\n",
    "print(\"WORK_DIR:\", WORK_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c370bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "import json\n",
    "\n",
    "def find_label_files(root: Path):\n",
    "    files = list(root.rglob(\"Labels-v2.json\"))\n",
    "    if not files:\n",
    "        files = list(root.rglob(\"Labels.json\"))\n",
    "    print(f\"Found label files: {len(files)}\")\n",
    "    return files\n",
    "\n",
    "def _parse_time_mmss(s: str):\n",
    "    parts = s.split(\":\")\n",
    "    try:\n",
    "        if len(parts)==3:\n",
    "            hh,mm,ss = parts; return int(hh)*3600 + int(mm)*60 + float(ss)\n",
    "        if len(parts)==2:\n",
    "            mm,ss = parts;    return int(mm)*60 + float(ss)\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def load_labels_with_half(labels_path: Path):\n",
    "    \"\"\"Return list of dicts: {'time_s': float, 'label': str, 'half': 0|1|2}\"\"\"\n",
    "    with open(labels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    ann = data.get(\"annotations\") or data.get(\"events\") or data.get(\"labels\") or []\n",
    "    out=[]\n",
    "    for ev in ann:\n",
    "        lab  = ev.get(\"label\") or ev.get(\"event\") or ev.get(\"type\")\n",
    "        if not lab:\n",
    "            continue\n",
    "        half = ev.get(\"half\")\n",
    "        if half not in (1,2):\n",
    "            gt = ev.get(\"gameTime\")\n",
    "            if isinstance(gt, str) and \" - \" in gt:\n",
    "                try: half = int(gt.split(\" - \")[0].strip())\n",
    "                except: half = None\n",
    "        pos = ev.get(\"position\")\n",
    "        t = None\n",
    "        if isinstance(pos,(int,float)): t = float(pos)\n",
    "        elif isinstance(pos,str):       t = _parse_time_mmss(pos)\n",
    "        if t is None:\n",
    "            gt = ev.get(\"gameTime\")\n",
    "            if isinstance(gt, str) and \" - \" in gt:\n",
    "                t = _parse_time_mmss(gt.split(\" - \")[1].strip())\n",
    "        if t is None:\n",
    "            continue\n",
    "        out.append({\"time_s\": float(t), \"label\": lab, \"half\": (half if half in (1,2) else 0)})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf08709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_half_videos(match_dir: Path):\n",
    "    \"\"\"Return {'1': Path|None, '2': Path|None, 'any': Path|None}\"\"\"\n",
    "    half_map = {1: None, 2: None}\n",
    "    any_vid = None\n",
    "    preferred = [\n",
    "        (\"1_720p.mkv\", 1), (\"2_720p.mkv\", 2),\n",
    "        (\"1_224p.mkv\", 1), (\"2_224p.mkv\", 2),\n",
    "        (\"1.mkv\", 1),     (\"2.mkv\", 2),\n",
    "        (\"1.mp4\", 1),     (\"2.mp4\", 2),\n",
    "    ]\n",
    "    for name, half in preferred:\n",
    "        p = match_dir / name\n",
    "        if p.exists():\n",
    "            half_map[half] = p\n",
    "            if any_vid is None: any_vid = p\n",
    "    if any_vid is None:\n",
    "        for ext in (\".mkv\",\".mp4\",\".m4v\",\".mov\"):\n",
    "            found = list(match_dir.glob(f\"*{ext}\"))\n",
    "            if found:\n",
    "                any_vid = found[0]; break\n",
    "    return {\"1\": half_map[1], \"2\": half_map[2], \"any\": any_vid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86efa989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found label files: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Index labels: 100%|██████████| 95/95 [00:00<00:00, 278.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed events: 20428\n",
      "Have video_path for: 9814 events\n",
      "Classes: ['Ball out of play', 'Clearance', 'Corner', 'Direct free-kick', 'Foul', 'Goal', 'Indirect free-kick', 'Kick-off', 'Offside', 'Penalty', 'Red card', 'Shots off target', 'Shots on target', 'Substitution', 'Throw-in', 'Yellow card', 'Yellow->red card'] | total: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rows=[]\n",
    "for lf in tqdm(find_label_files(SN_ROOT), desc=\"Index labels\"):\n",
    "    mdir  = lf.parent\n",
    "    split = mdir.parent.name\n",
    "    evs   = load_labels_with_half(lf)\n",
    "    if not evs:\n",
    "        continue\n",
    "    vids  = find_half_videos(mdir)  # may be all None if videos not yet downloaded\n",
    "    for e in evs:\n",
    "        # choose video by half when available, else fallback to any\n",
    "        video = vids[str(e[\"half\"])] if e[\"half\"] in (1,2) else vids[\"any\"]\n",
    "        rows.append({\n",
    "            \"split\": split,\n",
    "            \"match_dir\": str(mdir),\n",
    "            \"labels_json\": str(lf),\n",
    "            \"event_time_s\": e[\"time_s\"],\n",
    "            \"event_label\": e[\"label\"],\n",
    "            \"half\": int(e[\"half\"]),\n",
    "            \"video_path\": (str(video) if video is not None else None)\n",
    "        })\n",
    "\n",
    "df_events = pd.DataFrame(rows).drop_duplicates(\n",
    "    subset=[\"match_dir\",\"event_time_s\",\"event_label\",\"half\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Indexed events:\", len(df_events))\n",
    "print(\"Have video_path for:\", df_events[\"video_path\"].notna().sum(), \"events\")\n",
    "ALL_LABELS = sorted(df_events[\"event_label\"].unique())\n",
    "print(\"Classes:\", ALL_LABELS, \"| total:\", len(ALL_LABELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ac5822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoccerNet root: C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\n",
      "ERROR Unknown task: labels\n",
      "SoccerNet root: C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\n",
      "ERROR Unknown task: labels\n",
      "[Scan] Total video halves found: 95\n",
      " - england_epl\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\1_224p.mkv\n",
      " - england_epl\\2014-2015\\2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal\\1_224p.mkv\n",
      " - england_epl\\2014-2015\\2015-02-21 - 18-00 Swansea 2 - 1 Manchester United\\1_224p.mkv\n",
      " - england_epl\\2014-2015\\2015-02-22 - 19-15 Southampton 0 - 2 Liverpool\\1_224p.mkv\n",
      " - england_epl\\2014-2015\\2015-04-11 - 19-30 Burnley 0 - 1 Arsenal\\1_224p.mkv\n",
      " - england_epl\\2014-2015\\2015-05-17 - 18-00 Manchester United 1 - 1 Arsenal\\1_224p.mkv\n",
      " - england_epl\\2015-2016\\2015-08-08 - 19-30 Chelsea 2 - 2 Swansea\\1_224p.mkv\n",
      " - england_epl\\2015-2016\\2015-08-16 - 18-00 Manchester City 3 - 0 Chelsea\\1_224p.mkv\n",
      " - england_epl\\2015-2016\\2015-08-23 - 15-30 West Brom 2 - 3 Chelsea\\1_224p.mkv\n",
      " - england_epl\\2015-2016\\2015-08-29 - 17-00 Chelsea 1 - 2 Crystal Palace\\1_224p.mkv\n",
      "... and 85 more\n"
     ]
    }
   ],
   "source": [
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "from pathlib import Path\n",
    "\n",
    "# Create an instance, pointing to your dataset root\n",
    "mySoccerNetDownloader = SoccerNetDownloader(LocalDirectory=str(SN_ROOT))\n",
    "mySoccerNetDownloader.password = SOCCERNET_NDA  # 's0cc3rn3t'\n",
    "\n",
    "print(\"SoccerNet root:\", SN_ROOT)\n",
    "\n",
    "# ✅ Download labels (small files, safe)\n",
    "mySoccerNetDownloader.downloadDataTask(task=\"labels\", split=[\"train\",\"valid\",\"test\",\"challenge\"])\n",
    "\n",
    "# ✅ Download 224p halves, but exclude spain_laliga\n",
    "splits = [\"train\",\"valid\",\"test\",\"challenge\"]\n",
    "for s in splits:\n",
    "    split_dir = Path(SN_ROOT) / s\n",
    "    if not split_dir.exists():\n",
    "        continue\n",
    "    for comp_dir in split_dir.iterdir():\n",
    "        if not comp_dir.is_dir():\n",
    "            continue\n",
    "        if \"spain_laliga\" in comp_dir.name:\n",
    "            print(f\"⏭️ Skipping competition: {comp_dir}\")\n",
    "            continue\n",
    "        print(f\"⬇️ Downloading videos for competition: {comp_dir}\")\n",
    "        mySoccerNetDownloader.downloadGames(\n",
    "            files=[\"1_224p.mkv\", \"2_224p.mkv\"],\n",
    "            split=[s]\n",
    "        )\n",
    "# Create an instance, pointing to your dataset root\n",
    "mySoccerNetDownloader = SoccerNetDownloader(LocalDirectory=str(SN_ROOT))\n",
    "mySoccerNetDownloader.password = SOCCERNET_NDA  # 's0cc3rn3t'\n",
    "\n",
    "print(\"SoccerNet root:\", SN_ROOT)\n",
    "\n",
    "# ✅ Ensure labels are present (small JSON files, will skip if already exist)\n",
    "mySoccerNetDownloader.downloadDataTask(task=\"labels\", split=[\"train\",\"valid\",\"test\",\"challenge\"])\n",
    "\n",
    "# Instead: scan and list what’s already downloaded\n",
    "video_exts = {\".mkv\", \".mp4\", \".m4v\", \".mov\"}\n",
    "downloaded_videos = []\n",
    "for f in SN_ROOT.rglob(\"*\"):\n",
    "    if f.suffix in video_exts and f.name.startswith((\"1_\", \"2_\")):\n",
    "        downloaded_videos.append(f)\n",
    "\n",
    "print(f\"[Scan] Total video halves found: {len(downloaded_videos)}\")\n",
    "if downloaded_videos:\n",
    "    # Show just the first 10 to avoid huge spam\n",
    "    for v in sorted(downloaded_videos)[:10]:\n",
    "        print(\" -\", v.relative_to(SN_ROOT))\n",
    "    if len(downloaded_videos) > 10:\n",
    "        print(f\"... and {len(downloaded_videos)-10} more\")\n",
    "else:\n",
    "    print(\"⚠️ No video halves found. Check your dataset folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6239c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoccerNet root: C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\n",
      "ERROR Unknown task: labels\n",
      "[Labels] Games with labels found: 190\n",
      "✅ 'spain_laliga' not present — nothing to exclude.\n",
      "Keeping competitions: ['england_epl']\n",
      "[Scan] Kept games (labels): 190\n",
      "[Scan] Complete (both halves present): 0\n",
      "[Scan] Incomplete/missing: 190\n",
      "❌ No complete games found. If this is unexpected, double-check paths or consider downloading missing halves.\n",
      "Saved list of complete games to: sn_audio_work\\complete_games_224p.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re, shutil\n",
    "import pandas as pd\n",
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "\n",
    "# --- config ---\n",
    "NEEDED_FILES = [\"1_224p.mkv\", \"2_224p.mkv\"]\n",
    "DROP_COMP     = \"spain_laliga\"\n",
    "CANON_COMPS   = [\n",
    "    \"england_epl\",\n",
    "    \"europe_uefa-champions-league\",\n",
    "    \"france_ligue-1\",\n",
    "    \"germany_bundesliga\",\n",
    "    \"italy_serie-a\",\n",
    "]\n",
    "\n",
    "# --- helper: parse competition/season from your on-disk layout ---\n",
    "SEASON_RE = re.compile(r\"^\\d{4}-\\d{4}$\")\n",
    "def find_label_game_dirs(root: Path):\n",
    "    return [p.parent for p in root.rglob(\"Labels*.json\")]\n",
    "\n",
    "def parse_comp_season_from_game_dir(game_dir: Path, root: Path):\n",
    "    parts = game_dir.relative_to(root).parts\n",
    "    comp = None; season = None\n",
    "    for i, p in enumerate(parts):\n",
    "        if p in (set(CANON_COMPS) | {DROP_COMP}):\n",
    "            comp = p\n",
    "            if i+1 < len(parts) and SEASON_RE.match(parts[i+1]):\n",
    "                season = parts[i+1]\n",
    "            break\n",
    "    if comp is None and len(parts) >= 1:\n",
    "        comp = parts[0]\n",
    "    if season is None:\n",
    "        for p in parts:\n",
    "            if SEASON_RE.match(p): season = p; break\n",
    "    return comp, season\n",
    "\n",
    "def list_kept_game_dirs(root: Path, keep_comps: list[str]):\n",
    "    out = []\n",
    "    for gd in find_label_game_dirs(root):\n",
    "        comp, _ = parse_comp_season_from_game_dir(gd, root)\n",
    "        if comp in keep_comps:\n",
    "            out.append(gd)\n",
    "    return out\n",
    "\n",
    "def check_missing_halves(game_dirs: list[Path], need_files=NEEDED_FILES):\n",
    "    missing = []\n",
    "    have = 0\n",
    "    for g in game_dirs:\n",
    "        miss = [f for f in need_files if not (g / f).exists()]\n",
    "        if miss: missing.append((g, miss))\n",
    "        else:    have += 1\n",
    "    return have, missing\n",
    "\n",
    "# --- 0) Make a downloader instance (for labels if ever needed) ---\n",
    "mySoccerNetDownloader = SoccerNetDownloader(LocalDirectory=str(SN_ROOT))\n",
    "mySoccerNetDownloader.password = SOCCERNET_NDA\n",
    "\n",
    "print(\"SoccerNet root:\", SN_ROOT)\n",
    "\n",
    "# --- 1) Ensure labels exist (fast & small) ---\n",
    "# Safe to call repeatedly; it skips existing files.\n",
    "mySoccerNetDownloader.downloadDataTask(task=\"labels\", split=[\"train\",\"valid\",\"test\",\"challenge\"])\n",
    "\n",
    "# --- 2) Inventory competitions present from labels ---\n",
    "label_games = find_label_game_dirs(SN_ROOT)\n",
    "print(f\"[Labels] Games with labels found: {len(label_games)}\")\n",
    "\n",
    "inventory = {}\n",
    "for gd in label_games:\n",
    "    comp, season = parse_comp_season_from_game_dir(gd, SN_ROOT)\n",
    "    inventory.setdefault(comp, set())\n",
    "    if season: inventory[comp].add(season)\n",
    "\n",
    "# Warn if LaLiga exists; delete or ignore as you wish (here: just ignore printing)\n",
    "if DROP_COMP in inventory and len(inventory[DROP_COMP]) > 0:\n",
    "    print(f\"⚠️ Found '{DROP_COMP}' labels on disk. They will be excluded from processing.\")\n",
    "else:\n",
    "    print(\"✅ 'spain_laliga' not present — nothing to exclude.\")\n",
    "\n",
    "# --- 3) Build kept list (exclude LaLiga; keep canonical comps that exist) ---\n",
    "KEEP_COMPETITIONS = [c for c in CANON_COMPS if c in inventory]\n",
    "print(\"Keeping competitions:\", KEEP_COMPETITIONS)\n",
    "\n",
    "# --- 4) Filter to kept games and check which are complete (both halves) ---\n",
    "keep_game_dirs = list_kept_game_dirs(SN_ROOT, KEEP_COMPETITIONS)\n",
    "have_count, missing_list = check_missing_halves(keep_game_dirs, NEEDED_FILES)\n",
    "\n",
    "print(f\"[Scan] Kept games (labels): {len(keep_game_dirs)}\")\n",
    "print(f\"[Scan] Complete (both halves present): {have_count}\")\n",
    "print(f\"[Scan] Incomplete/missing: {len(missing_list)}\")\n",
    "\n",
    "# --- 5) Use ONLY the complete games; no further downloads requested ---\n",
    "complete_games = [g for g in keep_game_dirs if all((g/f).exists() for f in NEEDED_FILES)]\n",
    "\n",
    "# Small assertion/print\n",
    "if len(complete_games) == 0:\n",
    "    print(\"❌ No complete games found. If this is unexpected, double-check paths or consider downloading missing halves.\")\n",
    "else:\n",
    "    print(f\"✅ All data ready: using {len(complete_games)} complete games (excluding '{DROP_COMP}').\")\n",
    "\n",
    "# --- 6) Save list of complete game directories for downstream preprocessing ---\n",
    "complete_df = pd.DataFrame({\"game_dir\": [str(g) for g in complete_games]})\n",
    "COMPLETE_LIST_CSV = (WORK_DIR / \"complete_games_224p.csv\")\n",
    "complete_df.to_csv(COMPLETE_LIST_CSV, index=False)\n",
    "print(\"Saved list of complete games to:\", COMPLETE_LIST_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935c0c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games with labels found: 190\n",
      "Detected (split, competition) present from labels:\n",
      " - england_epl | 2014-2015\n",
      " - england_epl | 2015-2016\n",
      " - england_epl | 2016-2017\n",
      "Total competitions detected: 3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_label_game_dirs(root: Path):\n",
    "    \"\"\"Return list of game dirs that contain Labels*.json.\"\"\"\n",
    "    games = []\n",
    "    for p in root.rglob(\"Labels*.json\"):\n",
    "        # game dir = parent of label file\n",
    "        games.append(p.parent)\n",
    "    return games\n",
    "\n",
    "def list_competitions_from_labels(root: Path):\n",
    "    \"\"\"Return sorted list of (split, competition) tuples present on disk.\"\"\"\n",
    "    comps = set()\n",
    "    for game_dir in find_label_game_dirs(root):\n",
    "        # Expect: root / split / competition / season / game\n",
    "        parts = game_dir.relative_to(root).parts\n",
    "        if len(parts) >= 2:\n",
    "            split, competition = parts[0], parts[1]\n",
    "            comps.add((split, competition))\n",
    "    return sorted(comps)\n",
    "\n",
    "label_games = find_label_game_dirs(SN_ROOT)\n",
    "print(f\"Games with labels found: {len(label_games)}\")\n",
    "detected = list_competitions_from_labels(SN_ROOT)\n",
    "print(\"Detected (split, competition) present from labels:\")\n",
    "for s,c in detected[:15]:\n",
    "    print(\" -\", s, \"|\", c)\n",
    "print(\"Total competitions detected:\", len({c for _,c in detected}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbd5033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scan] Games with label JSONs under england_epl: 190\n",
      "[Result] EPL halves with labels: 380\n",
      "[Result] EPL halves READY (labels + WAV present): 78\n",
      "[Result] Missing WAV for 302 halves (show up to 5):\n",
      " - C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\\england_epl\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley  H2  expected: england_epl__2014-2015__2015-02-21 - 18-00 Chelsea 1 - 1 Burnley__H2_16000Hz.wav\n",
      " - C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\\england_epl\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley  H2  expected: england_epl__2014-2015__2015-02-21 - 18-00 Chelsea 1 - 1 Burnley__H2_16000Hz.wav\n",
      " - C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\\england_epl\\2014-2015\\2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal  H2  expected: england_epl__2014-2015__2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal__H2_16000Hz.wav\n",
      " - C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\\england_epl\\2014-2015\\2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal  H2  expected: england_epl__2014-2015__2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal__H2_16000Hz.wav\n",
      " - C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-project-520038655\\SoccerNet\\england_epl\\2014-2015\\2015-02-21 - 18-00 Swansea 2 - 1 Manchester United  H2  expected: england_epl__2014-2015__2015-02-21 - 18-00 Swansea 2 - 1 Manchester United__H2_16000Hz.wav\n",
      "\n",
      "Ready halves DataFrame shape: (78, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competition</th>\n",
       "      <th>season</th>\n",
       "      <th>game</th>\n",
       "      <th>game_dir</th>\n",
       "      <th>half</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>has_wav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-p...</td>\n",
       "      <td>1</td>\n",
       "      <td>sn_audio_work\\full_match_audio_wav\\england_epl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-p...</td>\n",
       "      <td>1</td>\n",
       "      <td>sn_audio_work\\full_match_audio_wav\\england_epl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal</td>\n",
       "      <td>C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-p...</td>\n",
       "      <td>1</td>\n",
       "      <td>sn_audio_work\\full_match_audio_wav\\england_epl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   competition     season                                             game  \\\n",
       "0  england_epl  2014-2015         2015-02-21 - 18-00 Chelsea 1 - 1 Burnley   \n",
       "1  england_epl  2014-2015         2015-02-21 - 18-00 Chelsea 1 - 1 Burnley   \n",
       "2  england_epl  2014-2015  2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal   \n",
       "\n",
       "                                            game_dir  half  \\\n",
       "0  C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-p...     1   \n",
       "1  C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-p...     1   \n",
       "2  C:\\Users\\CYBORG 15\\Documents\\GitHub\\elec5305-p...     1   \n",
       "\n",
       "                                            wav_path  has_wav  \n",
       "0  sn_audio_work\\full_match_audio_wav\\england_epl...     True  \n",
       "1  sn_audio_work\\full_match_audio_wav\\england_epl...     True  \n",
       "2  sn_audio_work\\full_match_audio_wav\\england_epl...     True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell: EPL inventory per HALF — available if (labels exist in that half) AND (WAV exists) ===\n",
    "from pathlib import Path\n",
    "import re, json\n",
    "import pandas as pd\n",
    "\n",
    "# Assumes SN_ROOT, AUDIO_DIR, TARGET_SR, TARGET_LABELS exist from earlier cells.\n",
    "# Fallbacks (safe defaults) if you ran this cell standalone:\n",
    "try:\n",
    "    SN_ROOT\n",
    "except NameError:\n",
    "    SN_ROOT = Path(r\"C:/path/to/SoccerNet\")  # <- set me if running standalone\n",
    "try:\n",
    "    WORK_DIR\n",
    "except NameError:\n",
    "    WORK_DIR  = Path(\"./sn_audio_work\")\n",
    "try:\n",
    "    AUDIO_DIR\n",
    "except NameError:\n",
    "    AUDIO_DIR = WORK_DIR / \"full_match_audio_wav\"\n",
    "try:\n",
    "    TARGET_SR\n",
    "except NameError:\n",
    "    TARGET_SR = 16000\n",
    "try:\n",
    "    TARGET_LABELS\n",
    "except NameError:\n",
    "    TARGET_LABELS = {\n",
    "        'Yellow->red card','Ball out of play','Foul','Indirect free-kick','Penalty','Shots off target',\n",
    "        'Offside','Yellow card','Red card','Goal','Direct free-kick','Substitution','Clearance',\n",
    "        'Kick-off','Corner','Throw-in','Shots on target'\n",
    "    }\n",
    "\n",
    "TARGET_COMP = \"england_epl\"\n",
    "SEASON_RE = re.compile(r\"^\\d{4}-\\d{4}$\")\n",
    "\n",
    "def parse_comp_season_from_game_dir(game_dir: Path, root: Path):\n",
    "    parts = game_dir.relative_to(root).parts\n",
    "    comp = None; season = None\n",
    "    for i, p in enumerate(parts):\n",
    "        if p == TARGET_COMP:\n",
    "            comp = p\n",
    "            if i+1 < len(parts) and SEASON_RE.match(parts[i+1]):\n",
    "                season = parts[i+1]\n",
    "            break\n",
    "    if comp is None and len(parts) >= 1:\n",
    "        comp = parts[0]\n",
    "    if season is None:\n",
    "        for p in parts:\n",
    "            if SEASON_RE.match(p):\n",
    "                season = p; break\n",
    "    return comp, season\n",
    "\n",
    "def find_label_game_dirs(root: Path):\n",
    "    \"\"\"All game dirs (any comp) that contain Labels*.json.\"\"\"\n",
    "    return [p.parent for p in root.rglob(\"Labels*.json\")]\n",
    "\n",
    "def _parse_time_mmss(s: str):\n",
    "    parts = s.split(\":\")\n",
    "    try:\n",
    "        if len(parts)==3:\n",
    "            hh,mm,ss = parts; return int(hh)*3600 + int(mm)*60 + float(ss)\n",
    "        if len(parts)==2:\n",
    "            mm,ss = parts;    return int(mm)*60 + float(ss)\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def load_labels_with_half(labels_path: Path):\n",
    "    \"\"\"Return list of dicts: {'time_s': float, 'label': str, 'half': int in {1,2}}.\"\"\"\n",
    "    with open(labels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    ann = data.get(\"annotations\") or data.get(\"events\") or data.get(\"labels\") or []\n",
    "    out=[]\n",
    "    for ev in ann:\n",
    "        lab  = ev.get(\"label\") or ev.get(\"event\") or ev.get(\"type\")\n",
    "        if not lab:\n",
    "            continue\n",
    "        half = ev.get(\"half\")\n",
    "        if half not in (1,2):\n",
    "            gt = ev.get(\"gameTime\")\n",
    "            if isinstance(gt, str) and \" - \" in gt:\n",
    "                try: half = int(gt.split(\" - \")[0].strip())\n",
    "                except: half = 1\n",
    "        pos = ev.get(\"position\")\n",
    "        t = None\n",
    "        if isinstance(pos,(int,float)): t = float(pos)\n",
    "        elif isinstance(pos,str):       t = _parse_time_mmss(pos)\n",
    "        if t is None:\n",
    "            gt = ev.get(\"gameTime\")\n",
    "            if isinstance(gt, str) and \" - \" in gt:\n",
    "                t = _parse_time_mmss(gt.split(\" - \")[1].strip())\n",
    "        if t is None: \n",
    "            continue\n",
    "        out.append({\"time_s\": float(t), \"label\": lab, \"half\": int(half)})\n",
    "    return out\n",
    "\n",
    "def expected_half_wav_path(comp: str, season: str, game: str, half: int, sr: int = TARGET_SR) -> Path:\n",
    "    # Must match your ensure_half_wav() naming\n",
    "    return AUDIO_DIR / f\"{comp}__{season}__{game}__H{half}_{sr}Hz.wav\"\n",
    "\n",
    "# ---- Build per-half availability ----\n",
    "label_games = [gd for gd in find_label_game_dirs(SN_ROOT) if parse_comp_season_from_game_dir(gd, SN_ROOT)[0] == TARGET_COMP]\n",
    "print(f\"[Scan] Games with label JSONs under {TARGET_COMP}: {len(label_games)}\")\n",
    "\n",
    "rows = []\n",
    "missing = []  # halves that have labels but WAV missing\n",
    "\n",
    "for gd in label_games:\n",
    "    comp, season = parse_comp_season_from_game_dir(gd, SN_ROOT)\n",
    "    game = gd.name\n",
    "    labels_json = (gd / \"Labels-v2.json\") if (gd / \"Labels-v2.json\").exists() else (gd / \"Labels.json\")\n",
    "\n",
    "    # Which halves have at least one TARGET_LABEL event?\n",
    "    try:\n",
    "        evs = load_labels_with_half(labels_json)\n",
    "    except Exception as e:\n",
    "        # if label file unparsable, skip this game\n",
    "        continue\n",
    "    halves_with_labels = sorted({e[\"half\"] for e in evs if e[\"label\"] in TARGET_LABELS})\n",
    "\n",
    "    for h in halves_with_labels:\n",
    "        wav_p = expected_half_wav_path(comp, season, game, h, TARGET_SR)\n",
    "        if wav_p.exists():\n",
    "            rows.append({\n",
    "                \"competition\": comp,\n",
    "                \"season\": season,\n",
    "                \"game\": game,\n",
    "                \"game_dir\": str(gd),\n",
    "                \"half\": h,\n",
    "                \"wav_path\": str(wav_p),\n",
    "                \"has_wav\": True\n",
    "            })\n",
    "        else:\n",
    "            missing.append((gd, h, wav_p))\n",
    "            rows.append({\n",
    "                \"competition\": comp,\n",
    "                \"season\": season,\n",
    "                \"game\": game,\n",
    "                \"game_dir\": str(gd),\n",
    "                \"half\": h,\n",
    "                \"wav_path\": str(wav_p),\n",
    "                \"has_wav\": False\n",
    "            })\n",
    "\n",
    "df_halves = pd.DataFrame(rows).sort_values([\"season\",\"game\",\"half\"]).reset_index(drop=True)\n",
    "\n",
    "n_halves_with_labels = len(df_halves)\n",
    "n_available = int(df_halves[\"has_wav\"].sum())\n",
    "print(f\"[Result] EPL halves with labels: {n_halves_with_labels}\")\n",
    "print(f\"[Result] EPL halves READY (labels + WAV present): {n_available}\")\n",
    "print(f\"[Result] Missing WAV for {n_halves_with_labels - n_available} halves (show up to 5):\")\n",
    "for gd, h, wp in missing[:5]:\n",
    "    print(f\" - {gd}  H{h}  expected: {wp.name}\")\n",
    "\n",
    "# Optional: keep only the ready halves for downstream use\n",
    "df_halves_ready = df_halves[df_halves[\"has_wav\"]].reset_index(drop=True)\n",
    "print(f\"\\nReady halves DataFrame shape: {df_halves_ready.shape}\")\n",
    "df_halves_ready.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ef5d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Index labels: 100%|██████████| 190/190 [00:01<00:00, 107.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Events] Kept (labels + half WAV exists): 3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Make/collect clips + mels:   2%|▏         | 94/3969 [00:00<00:19, 198.62it/s]C:\\Users\\CYBORG 15\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "Make/collect clips + mels: 100%|██████████| 3969/3969 [00:30<00:00, 131.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Updated index → sn_audio_work\\dataset_index.csv (old 7938 + new 7937 → unique 7938)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competition</th>\n",
       "      <th>season</th>\n",
       "      <th>game</th>\n",
       "      <th>half</th>\n",
       "      <th>t_center_s</th>\n",
       "      <th>win_s</th>\n",
       "      <th>event_label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>audio_wav</th>\n",
       "      <th>mel_npy</th>\n",
       "      <th>frames</th>\n",
       "      <th>n_mels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Kick-off</td>\n",
       "      <td>7</td>\n",
       "      <td>sn_audio_work\\clips\\win15s\\england_epl__2014-2...</td>\n",
       "      <td>sn_audio_work\\mel64\\win15s\\england_epl__2014-2...</td>\n",
       "      <td>751</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Kick-off</td>\n",
       "      <td>7</td>\n",
       "      <td>sn_audio_work\\clips\\win30s\\england_epl__2014-2...</td>\n",
       "      <td>sn_audio_work\\mel64\\win30s\\england_epl__2014-2...</td>\n",
       "      <td>1501</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Ball out of play</td>\n",
       "      <td>0</td>\n",
       "      <td>sn_audio_work\\clips\\win15s\\england_epl__2014-2...</td>\n",
       "      <td>sn_audio_work\\mel64\\win15s\\england_epl__2014-2...</td>\n",
       "      <td>751</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Ball out of play</td>\n",
       "      <td>0</td>\n",
       "      <td>sn_audio_work\\clips\\win30s\\england_epl__2014-2...</td>\n",
       "      <td>sn_audio_work\\mel64\\win30s\\england_epl__2014-2...</td>\n",
       "      <td>1501</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>england_epl</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>2015-02-21 - 18-00 Chelsea 1 - 1 Burnley</td>\n",
       "      <td>1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Throw-in</td>\n",
       "      <td>14</td>\n",
       "      <td>sn_audio_work\\clips\\win15s\\england_epl__2014-2...</td>\n",
       "      <td>sn_audio_work\\mel64\\win15s\\england_epl__2014-2...</td>\n",
       "      <td>751</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   competition     season                                      game  half  \\\n",
       "0  england_epl  2014-2015  2015-02-21 - 18-00 Chelsea 1 - 1 Burnley     1   \n",
       "1  england_epl  2014-2015  2015-02-21 - 18-00 Chelsea 1 - 1 Burnley     1   \n",
       "2  england_epl  2014-2015  2015-02-21 - 18-00 Chelsea 1 - 1 Burnley     1   \n",
       "3  england_epl  2014-2015  2015-02-21 - 18-00 Chelsea 1 - 1 Burnley     1   \n",
       "4  england_epl  2014-2015  2015-02-21 - 18-00 Chelsea 1 - 1 Burnley     1   \n",
       "\n",
       "   t_center_s  win_s       event_label  label_id  \\\n",
       "0         0.0     15          Kick-off         7   \n",
       "1         0.0     30          Kick-off         7   \n",
       "2       133.0     15  Ball out of play         0   \n",
       "3       133.0     30  Ball out of play         0   \n",
       "4       149.0     15          Throw-in        14   \n",
       "\n",
       "                                           audio_wav  \\\n",
       "0  sn_audio_work\\clips\\win15s\\england_epl__2014-2...   \n",
       "1  sn_audio_work\\clips\\win30s\\england_epl__2014-2...   \n",
       "2  sn_audio_work\\clips\\win15s\\england_epl__2014-2...   \n",
       "3  sn_audio_work\\clips\\win30s\\england_epl__2014-2...   \n",
       "4  sn_audio_work\\clips\\win15s\\england_epl__2014-2...   \n",
       "\n",
       "                                             mel_npy  frames  n_mels  \n",
       "0  sn_audio_work\\mel64\\win15s\\england_epl__2014-2...     751      64  \n",
       "1  sn_audio_work\\mel64\\win30s\\england_epl__2014-2...    1501      64  \n",
       "2  sn_audio_work\\mel64\\win15s\\england_epl__2014-2...     751      64  \n",
       "3  sn_audio_work\\mel64\\win30s\\england_epl__2014-2...    1501      64  \n",
       "4  sn_audio_work\\mel64\\win15s\\england_epl__2014-2...     751      64  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Build clips + mel features + dataset_index.csv (idempotent + atomic saves + corruption repair) ===\n",
    "import os, re, json, math, numpy as np, pandas as pd, torch, torchaudio, tempfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Config (reuse if already defined) ----\n",
    "SN_ROOT   = Path(globals().get(\"SN_ROOT\", r\"C:/Users/YourUser/SoccerNet\"))      # << set if needed\n",
    "WORK_DIR  = Path(globals().get(\"WORK_DIR\", \"./sn_audio_work\"))\n",
    "AUDIO_DIR = Path(globals().get(\"AUDIO_DIR\", WORK_DIR / \"full_match_audio_wav\"))\n",
    "CLIPS_DIR = Path(globals().get(\"CLIPS_DIR\", WORK_DIR / \"clips\")); CLIPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FEAT_DIR  = Path(globals().get(\"FEAT_DIR\",  WORK_DIR / \"mel64\"));  FEAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INDEX_CSV = Path(globals().get(\"INDEX_CSV\", WORK_DIR / \"dataset_index.csv\"))\n",
    "\n",
    "TARGET_COMP = \"england_epl\"\n",
    "TARGET_SR   = int(globals().get(\"TARGET_SR\", 16000))\n",
    "N_MELS      = int(globals().get(\"N_MELS\", 64))\n",
    "N_FFT       = int(globals().get(\"N_FFT\", 1024))\n",
    "HOP         = int(globals().get(\"HOP\", 320))\n",
    "WINDOWS     = list(globals().get(\"WINDOWS\", [15, 30]))\n",
    "\n",
    "# Idempotency & repair controls\n",
    "OVERWRITE_MELS    = False     # force recompute even if present\n",
    "OVERWRITE_WAVS    = False     # force rewrite clip wavs\n",
    "REPAIR_CORRUPT    = True      # recompute invalid/partial npy files\n",
    "VALIDATE_NPY_SHAPE = (N_MELS, None)  # expected (n_mels, T). None = any T\n",
    "\n",
    "TARGET_LABELS = set(globals().get(\"TARGET_LABELS\", {\n",
    "    'Yellow->red card','Ball out of play','Foul','Indirect free-kick','Penalty','Shots off target',\n",
    "    'Offside','Yellow card','Red card','Goal','Direct free-kick','Substitution','Clearance',\n",
    "    'Kick-off','Corner','Throw-in','Shots on target'\n",
    "}))\n",
    "\n",
    "SEASON_RE = re.compile(r\"^\\d{4}-\\d{4}$\")\n",
    "\n",
    "def _parse_time_mmss(s: str):\n",
    "    parts = s.split(\":\")\n",
    "    try:\n",
    "        if len(parts)==3: hh,mm,ss = parts; return int(hh)*3600 + int(mm)*60 + float(ss)\n",
    "        if len(parts)==2: mm,ss = parts; return int(mm)*60 + float(ss)\n",
    "    except Exception: return None\n",
    "    return None\n",
    "\n",
    "def parse_comp_season_from_game_dir(game_dir: Path, root: Path):\n",
    "    parts = game_dir.relative_to(root).parts\n",
    "    comp = None; season = None\n",
    "    for i, p in enumerate(parts):\n",
    "        if p == TARGET_COMP:\n",
    "            comp = p\n",
    "            if i+1 < len(parts) and SEASON_RE.match(parts[i+1]): season = parts[i+1]\n",
    "            break\n",
    "    if comp is None and len(parts) >= 1: comp = parts[0]\n",
    "    if season is None:\n",
    "        for p in parts:\n",
    "            if SEASON_RE.match(p): season = p; break\n",
    "    return comp, season\n",
    "\n",
    "def find_label_game_dirs(root: Path):\n",
    "    return [p.parent for p in root.rglob(\"Labels*.json\")]\n",
    "\n",
    "def load_labels_with_half(labels_path: Path):\n",
    "    with open(labels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    ann = data.get(\"annotations\") or data.get(\"events\") or data.get(\"labels\") or []\n",
    "    out=[]\n",
    "    for ev in ann:\n",
    "        lab  = ev.get(\"label\") or ev.get(\"event\") or ev.get(\"type\")\n",
    "        if not lab: continue\n",
    "        half = ev.get(\"half\")\n",
    "        if half not in (1,2):\n",
    "            gt = ev.get(\"gameTime\")\n",
    "            if isinstance(gt, str) and \" - \" in gt:\n",
    "                try: half = int(gt.split(\" - \")[0].strip())\n",
    "                except: half = 1\n",
    "        pos = ev.get(\"position\")\n",
    "        t = float(pos) if isinstance(pos,(int,float)) else (_parse_time_mmss(pos) if isinstance(pos,str) else None)\n",
    "        if t is None:\n",
    "            gt = ev.get(\"gameTime\")\n",
    "            if isinstance(gt, str) and \" - \" in gt:\n",
    "                t = _parse_time_mmss(gt.split(\" - \")[1].strip())\n",
    "        if t is None: continue\n",
    "        out.append({\"time_s\": float(t), \"label\": lab, \"half\": int(half)})\n",
    "    return out\n",
    "\n",
    "def expected_half_wav_path(comp: str, season: str, game: str, half: int, sr: int = TARGET_SR) -> Path:\n",
    "    return AUDIO_DIR / f\"{comp}__{season}__{game}__H{half}_{sr}Hz.wav\"\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"-\", s.strip().lower()).strip(\"-\")\n",
    "\n",
    "# ---- Atomic save helpers ----\n",
    "def atomic_save_npy(path: Path, arr: np.ndarray):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, dir=str(path.parent), suffix=\".tmp\") as tf:\n",
    "        tmp = Path(tf.name)\n",
    "    try:\n",
    "        np.save(tmp, arr, allow_pickle=False)\n",
    "        os.replace(tmp, path)  # atomic on Windows/Unix\n",
    "    finally:\n",
    "        if tmp.exists():\n",
    "            try: tmp.unlink()\n",
    "            except: pass\n",
    "\n",
    "def atomic_save_wav(path: Path, tensor: torch.Tensor, sr: int):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, dir=str(path.parent), suffix=\".tmp.wav\") as tf:\n",
    "        tmp = Path(tf.name)\n",
    "    try:\n",
    "        torchaudio.save(str(tmp), tensor, sr)\n",
    "        os.replace(tmp, path)\n",
    "    finally:\n",
    "        if tmp.exists():\n",
    "            try: tmp.unlink()\n",
    "            except: pass\n",
    "\n",
    "def is_valid_npy(path: Path, expected_first_dim: int | None = None) -> bool:\n",
    "    try:\n",
    "        if not path.exists() or path.stat().st_size == 0:\n",
    "            return False\n",
    "        arr = np.load(path, mmap_mode=\"r\")\n",
    "        if arr.ndim != 2:\n",
    "            return False\n",
    "        if expected_first_dim is not None and arr.shape[0] != expected_first_dim:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ---------- 1) Collect EPL events with existing half WAV ----------\n",
    "label_games = [gd for gd in find_label_game_dirs(SN_ROOT) if parse_comp_season_from_game_dir(gd, SN_ROOT)[0] == TARGET_COMP]\n",
    "rows=[]\n",
    "for gd in tqdm(label_games, desc=\"Index labels\"):\n",
    "    comp, season = parse_comp_season_from_game_dir(gd, SN_ROOT)\n",
    "    game = gd.name\n",
    "    labels_json = (gd / \"Labels-v2.json\") if (gd / \"Labels-v2.json\").exists() else (gd / \"Labels.json\")\n",
    "    evs = load_labels_with_half(labels_json)\n",
    "    for e in evs:\n",
    "        if e[\"label\"] not in TARGET_LABELS: continue\n",
    "        wav_p = expected_half_wav_path(comp, season, game, e[\"half\"], TARGET_SR)\n",
    "        if wav_p.exists():\n",
    "            rows.append({\n",
    "                \"competition\": comp, \"season\": season, \"game\": game, \"game_dir\": str(gd),\n",
    "                \"event_time_s\": e[\"time_s\"], \"event_label\": e[\"label\"], \"half\": e[\"half\"],\n",
    "                \"audio_wav\": str(wav_p)\n",
    "            })\n",
    "df_events = pd.DataFrame(rows).drop_duplicates(subset=[\"game_dir\",\"event_time_s\",\"event_label\",\"half\"]).reset_index(drop=True)\n",
    "print(f\"[Events] Kept (labels + half WAV exists): {len(df_events)}\")\n",
    "if df_events.empty:\n",
    "    raise SystemExit(\"No events with matching half WAVs found. Put some WAVs in full_match_audio_wav/.\")\n",
    "\n",
    "# ---------- 2) Mel frontend ----------\n",
    "mel_tf = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=TARGET_SR, n_fft=N_FFT, hop_length=HOP, win_length=N_FFT,\n",
    "    n_mels=N_MELS, f_min=0.0, f_max=TARGET_SR/2.0, center=True, pad_mode=\"reflect\", power=2.0\n",
    ")\n",
    "amp2db = torchaudio.transforms.AmplitudeToDB(stype=\"power\")\n",
    "\n",
    "def load_half_wav_cached(wav_path: str, cache: dict) -> torch.Tensor:\n",
    "    if wav_path in cache: return cache[wav_path]\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
    "    if sr != TARGET_SR:  wav = torchaudio.functional.resample(wav, sr, TARGET_SR)\n",
    "    cache[wav_path] = wav.squeeze(0).contiguous()\n",
    "    return cache[wav_path]\n",
    "\n",
    "def cut_centered(signal_1d: torch.Tensor, sr: int, center_s: float, win_s: float) -> torch.Tensor:\n",
    "    total = signal_1d.numel()\n",
    "    n_win = int(round(win_s * sr))\n",
    "    half = n_win // 2\n",
    "    center = int(round(center_s * sr))\n",
    "    start = center - half\n",
    "    end   = start + n_win\n",
    "    pad_left = max(0, -start)\n",
    "    pad_right = max(0, end - total)\n",
    "    if pad_left or pad_right:\n",
    "        sig = torch.nn.functional.pad(signal_1d, (pad_left, pad_right))\n",
    "        start = start + pad_left\n",
    "        end   = start + n_win\n",
    "        clip = sig[start:end]\n",
    "    else:\n",
    "        start = max(0, start); end = min(total, end)\n",
    "        clip = signal_1d[start:end]\n",
    "    if clip.numel() != n_win:\n",
    "        clip = torch.nn.functional.pad(clip, (0, n_win - clip.numel()))\n",
    "    return clip\n",
    "\n",
    "# Ensure folders exist\n",
    "for w in WINDOWS:\n",
    "    (CLIPS_DIR / f\"win{w}s\").mkdir(parents=True, exist_ok=True)\n",
    "    (FEAT_DIR  / f\"win{w}s\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- 3) Generate clips + mels + CSV (skip existing + repair corrupt) ----------\n",
    "rows_out = []\n",
    "wav_cache = {}\n",
    "labels_sorted = sorted(df_events[\"event_label\"].unique())\n",
    "label_to_id = {lab:i for i,lab in enumerate(labels_sorted)}\n",
    "\n",
    "pbar = tqdm(df_events.itertuples(index=False), total=len(df_events), desc=\"Make/collect clips + mels\")\n",
    "for r in pbar:\n",
    "    comp, season, game = r.competition, r.season, r.game\n",
    "    half, t_s = int(r.half), float(r.event_time_s)\n",
    "    label     = r.event_label\n",
    "    label_id  = label_to_id[label]\n",
    "    half_wav  = r.audio_wav\n",
    "\n",
    "    # Decide which windows actually need recompute (missing or corrupt or overwrite)\n",
    "    plan_windows = []\n",
    "    for win_s in WINDOWS:\n",
    "        stem = f\"{comp}__{season}__{game}__H{half}__{slugify(label)}__t{int(round(t_s*1000))}ms__w{win_s}s\"\n",
    "        wav_out  = CLIPS_DIR / f\"win{win_s}s\" / f\"{stem}.wav\"\n",
    "        mel_out  = FEAT_DIR  / f\"win{win_s}s\" / f\"{stem}.npy\"\n",
    "\n",
    "        mel_exists = mel_out.exists()\n",
    "        mel_valid  = is_valid_npy(mel_out, expected_first_dim=VALIDATE_NPY_SHAPE[0]) if mel_exists else False\n",
    "        need_mel   = OVERWRITE_MELS or (not mel_exists) or (REPAIR_CORRUPT and not mel_valid)\n",
    "\n",
    "        if need_mel:\n",
    "            plan_windows.append((win_s, stem, wav_out, mel_out))\n",
    "\n",
    "    # If nothing to do, just consume existing valid mels\n",
    "    if not plan_windows:\n",
    "        for win_s in WINDOWS:\n",
    "            stem = f\"{comp}__{season}__{game}__H{half}__{slugify(label)}__t{int(round(t_s*1000))}ms__w{win_s}s\"\n",
    "            wav_out  = CLIPS_DIR / f\"win{win_s}s\" / f\"{stem}.wav\"\n",
    "            mel_out  = FEAT_DIR  / f\"win{win_s}s\" / f\"{stem}.npy\"\n",
    "            if is_valid_npy(mel_out, expected_first_dim=N_MELS):\n",
    "                mel = np.load(mel_out, mmap_mode=\"r\")\n",
    "                rows_out.append({\n",
    "                    \"competition\": comp, \"season\": season, \"game\": game, \"half\": half,\n",
    "                    \"t_center_s\": t_s, \"win_s\": win_s, \"event_label\": label, \"label_id\": label_id,\n",
    "                    \"audio_wav\": str(wav_out), \"mel_npy\": str(mel_out),\n",
    "                    \"frames\": int(mel.shape[1]), \"n_mels\": int(mel.shape[0]),\n",
    "                })\n",
    "        continue\n",
    "\n",
    "    # Work needed → load half once\n",
    "    full = load_half_wav_cached(half_wav, wav_cache)\n",
    "\n",
    "    # Compute/rewrite for the windows that need it\n",
    "    for (win_s, stem, wav_out, mel_out) in plan_windows:\n",
    "        clip = cut_centered(full, TARGET_SR, t_s, win_s)\n",
    "\n",
    "        if OVERWRITE_WAVS or (not wav_out.exists()):\n",
    "            atomic_save_wav(wav_out, clip.unsqueeze(0), TARGET_SR)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mel = mel_tf(clip.unsqueeze(0))\n",
    "            mel_db = amp2db(mel).squeeze(0).cpu().numpy()\n",
    "            mu, sd = mel_db.mean(), mel_db.std() + 1e-8\n",
    "            mel_db = (mel_db - mu) / sd\n",
    "\n",
    "        atomic_save_npy(mel_out, mel_db)\n",
    "\n",
    "    # Append rows for all windows (now guaranteed valid)\n",
    "    for win_s in WINDOWS:\n",
    "        stem = f\"{comp}__{season}__{game}__H{half}__{slugify(label)}__t{int(round(t_s*1000))}ms__w{win_s}s\"\n",
    "        wav_out  = CLIPS_DIR / f\"win{win_s}s\" / f\"{stem}.wav\"\n",
    "        mel_out  = FEAT_DIR  / f\"win{win_s}s\" / f\"{stem}.npy\"\n",
    "        if is_valid_npy(mel_out, expected_first_dim=N_MELS):\n",
    "            mel = np.load(mel_out, mmap_mode=\"r\")\n",
    "            rows_out.append({\n",
    "                \"competition\": comp, \"season\": season, \"game\": game, \"half\": half,\n",
    "                \"t_center_s\": t_s, \"win_s\": win_s, \"event_label\": label, \"label_id\": label_id,\n",
    "                \"audio_wav\": str(wav_out), \"mel_npy\": str(mel_out),\n",
    "                \"frames\": int(mel.shape[1]), \"n_mels\": int(mel.shape[0]),\n",
    "            })\n",
    "\n",
    "# ---------- 4) Merge/build index ----------\n",
    "new_index = pd.DataFrame(rows_out).sort_values(\n",
    "    [\"season\",\"game\",\"half\",\"t_center_s\",\"win_s\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "if INDEX_CSV.exists():\n",
    "    old_index = pd.read_csv(INDEX_CSV)\n",
    "    combo = pd.concat([old_index, new_index], ignore_index=True)\n",
    "    combo.drop_duplicates(subset=[\"mel_npy\"], inplace=True)\n",
    "    combo.sort_values([\"season\",\"game\",\"half\",\"t_center_s\",\"win_s\"], inplace=True)\n",
    "    combo.reset_index(drop=True, inplace=True)\n",
    "    combo.to_csv(INDEX_CSV, index=False)\n",
    "    print(f\"[Done] Updated index → {INDEX_CSV} (old {len(old_index)} + new {len(new_index)} → unique {len(combo)})\")\n",
    "    display(combo.head(5))\n",
    "else:\n",
    "    new_index.to_csv(INDEX_CSV, index=False)\n",
    "    print(f\"[Done] Wrote {len(new_index)} rows → {INDEX_CSV}\")\n",
    "    display(new_index.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3d807",
   "metadata": {},
   "source": [
    "**PART 2: Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46986372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORG 15\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\__init__.py:16: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.3)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# === RCNN baseline: setup ===\n",
    "import os, math, json, time, random, re, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# Paths (re-use your earlier ones)\n",
    "WORK_DIR  = Path(\"./sn_audio_work\")\n",
    "INDEX_CSV = WORK_DIR / \"dataset_index.csv\"  # created by your mel feature cell\n",
    "\n",
    "# Repro & device\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Training config\n",
    "WIN_S            = 30       # choose 15 or 30 to match what you saved\n",
    "BATCH_SIZE       = 16\n",
    "NUM_EPOCHS       = 20\n",
    "LR               = 2e-4\n",
    "WEIGHT_DECAY     = 1e-4\n",
    "LABEL_SMOOTHING  = 0.05\n",
    "USE_MIXED_PREC   = True\n",
    "NUM_WORKERS      = 2\n",
    "\n",
    "# SpecAugment-lite\n",
    "AUG_FREQ_MASKS   = 1   # 0 to disable\n",
    "AUG_FREQ_WIDTH   = 8\n",
    "AUG_TIME_MASKS   = 1\n",
    "AUG_TIME_WIDTH   = 24  # frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68359ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124\n",
      "cuda available: True\n",
      "build cuda: 12.4\n",
      "device count: 1\n",
      "gpu0: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"build cuda:\", torch.version.cuda)\n",
    "print(\"device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available(): print(\"gpu0:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b35379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 16 ['Ball out of play', 'Clearance', 'Corner', 'Direct free-kick', 'Foul', 'Goal', 'Indirect free-kick', 'Kick-off', 'Offside', 'Penalty'] ...\n",
      "Train clips: 3172  |  Val clips: 797  | Games train/val: 31/8\n"
     ]
    }
   ],
   "source": [
    "# === Load dataset index and split ===\n",
    "df = pd.read_csv(INDEX_CSV)\n",
    "df = df[df[\"win_s\"] == WIN_S].copy()\n",
    "\n",
    "# Only valid rows with existing feature files\n",
    "df = df[df[\"mel_npy\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)\n",
    "\n",
    "# Classes\n",
    "labels_sorted = sorted(df[\"event_label\"].unique())\n",
    "label_to_id   = {lab:i for i, lab in enumerate(labels_sorted)}\n",
    "id_to_label   = {i:lab for lab,i in label_to_id.items()}\n",
    "num_classes   = len(labels_sorted)\n",
    "print(\"Classes:\", num_classes, labels_sorted[:10], \"...\")\n",
    "\n",
    "# Encode labels\n",
    "df[\"y\"] = df[\"event_label\"].map(label_to_id)\n",
    "\n",
    "# Split by game (season+game combo) to reduce leakage\n",
    "df[\"game_key\"] = df[\"season\"].astype(str) + \"/\" + df[\"game\"].astype(str)\n",
    "games = df[\"game_key\"].unique().tolist()\n",
    "random.shuffle(games)\n",
    "\n",
    "n_train = int(0.8 * len(games))\n",
    "train_games = set(games[:n_train])\n",
    "val_games   = set(games[n_train:])\n",
    "\n",
    "train_df = df[df[\"game_key\"].isin(train_games)].reset_index(drop=True)\n",
    "val_df   = df[df[\"game_key\"].isin(val_games)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train clips: {len(train_df)}  |  Val clips: {len(val_df)}  | Games train/val: {len(train_games)}/{len(val_games)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fdae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders ready.\n"
     ]
    }
   ],
   "source": [
    "# === Dataset & collate ===\n",
    "class MelClipDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects mel_npy shaped [n_mels, T], z-scored per clip (as created earlier).\n",
    "    Applies light SpecAugment on-the-fly (optional).\n",
    "    \"\"\"\n",
    "    def __init__(self, frame, train=True, aug_freq_masks=0, aug_freq_w=8, aug_time_masks=0, aug_time_w=24):\n",
    "        self.frame = frame\n",
    "        self.train = train\n",
    "        self.aug_freq_masks = aug_freq_masks if train else 0\n",
    "        self.aug_freq_w     = aug_freq_w\n",
    "        self.aug_time_masks = aug_time_masks if train else 0\n",
    "        self.aug_time_w     = aug_time_w\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def _spec_augment(self, m):\n",
    "        # m: [n_mels, T]\n",
    "        n_mels, T = m.shape\n",
    "        out = m.copy()\n",
    "\n",
    "        # Frequency masks\n",
    "        for _ in range(self.aug_freq_masks):\n",
    "            w = random.randint(1, min(self.aug_freq_w, n_mels // 2))\n",
    "            f0 = random.randint(0, max(0, n_mels - w))\n",
    "            out[f0:f0+w, :] = 0.0\n",
    "\n",
    "        # Time masks\n",
    "        for _ in range(self.aug_time_masks):\n",
    "            w = random.randint(1, min(self.aug_time_w, T // 2))\n",
    "            t0 = random.randint(0, max(0, T - w))\n",
    "            out[:, t0:t0+w] = 0.0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.frame.iloc[idx]\n",
    "        mel = np.load(r[\"mel_npy\"])  # [n_mels, T] float32-ish\n",
    "        if self.train:\n",
    "            mel = self._spec_augment(mel)\n",
    "        # to tensor [C=1, n_mels, T]\n",
    "        x = torch.from_numpy(mel).float().unsqueeze(0)\n",
    "        y = int(r[\"y\"])\n",
    "        meta = {\n",
    "            \"competition\": r[\"competition\"],\n",
    "            \"season\": r[\"season\"],\n",
    "            \"game\": r[\"game\"],\n",
    "            \"half\": int(r[\"half\"]),\n",
    "            \"t_center_s\": float(r[\"t_center_s\"]),\n",
    "            \"label\": r[\"event_label\"],\n",
    "        }\n",
    "        return x, y, meta\n",
    "\n",
    "def pad_time_collate(batch):\n",
    "    \"\"\"\n",
    "    Pad variable T to max_T in the batch on the right; returns:\n",
    "    x: [B, 1, n_mels, T_max], y: [B], lengths: [B]\n",
    "    \"\"\"\n",
    "    xs, ys, metas = zip(*batch)\n",
    "    n_mels = xs[0].shape[1]\n",
    "    lengths = torch.tensor([t.shape[-1] for t in xs], dtype=torch.long)\n",
    "    T_max = int(lengths.max())\n",
    "\n",
    "    x_padded = torch.zeros(len(xs), 1, n_mels, T_max, dtype=torch.float32)\n",
    "    for i, t in enumerate(xs):\n",
    "        T = t.shape[-1]\n",
    "        x_padded[i, :, :, :T] = t\n",
    "\n",
    "    y = torch.tensor(ys, dtype=torch.long)\n",
    "    return x_padded, y, lengths, metas\n",
    "\n",
    "train_ds = MelClipDataset(train_df, train=True,\n",
    "                          aug_freq_masks=AUG_FREQ_MASKS, aug_freq_w=AUG_FREQ_WIDTH,\n",
    "                          aug_time_masks=AUG_TIME_MASKS, aug_time_w=AUG_TIME_WIDTH)\n",
    "val_ds   = MelClipDataset(val_df,   train=False)\n",
    "\n",
    "# Weighted sampler for class imbalance\n",
    "class_counts = train_df[\"y\"].value_counts().reindex(range(num_classes), fill_value=0).values\n",
    "class_weights = 1.0 / (class_counts + 1e-6)\n",
    "sample_weights = train_df[\"y\"].map(lambda yi: class_weights[yi]).values\n",
    "sampler = WeightedRandomSampler(weights=torch.from_numpy(sample_weights).float(),\n",
    "                                num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=pad_time_collate)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True, collate_fn=pad_time_collate)\n",
    "\n",
    "print(\"Loaders ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0c139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.399344"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === RCNN model ===\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, pool=(2,2), p_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(pool)\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class RCNN_Audio(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: [B, 1, n_mels, T]\n",
    "    Conv downsamples in freq/time; then BiGRU over time; then pool and classify.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_mels, n_classes, rnn_hidden=128, rnn_layers=1, use_attention=False):\n",
    "        super().__init__()\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        # 2 lightweight conv blocks (keep it small for your GPU)\n",
    "        self.feat = nn.Sequential(\n",
    "            ConvBlock(1, 32, pool=(2,2), p_drop=0.1),   # -> [B,32,n_mels/2,T/2]\n",
    "            ConvBlock(32, 64, pool=(2,2), p_drop=0.1),  # -> [B,64,n_mels/4,T/4]\n",
    "        )\n",
    "\n",
    "        # Project freq dimension to a feature dim for RNN\n",
    "        self.proj = nn.Conv2d(64, 128, kernel_size=(n_mels//4, 1))  # collapse freq\n",
    "        # Now shape: [B,128,1,T’] -> squeeze freq -> [B,128,T’]\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=128, hidden_size=rnn_hidden, num_layers=rnn_layers,\n",
    "                          batch_first=True, dropout=0.0, bidirectional=True)\n",
    "\n",
    "        if use_attention:\n",
    "            self.attn = nn.Linear(2*rnn_hidden, 1)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(2*rnn_hidden),\n",
    "            nn.Linear(2*rnn_hidden, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        # x: [B, 1, n_mels, T]\n",
    "        B = x.size(0)\n",
    "        x = self.feat(x)                           # [B,64,n_mels/4,T’]\n",
    "        x = self.proj(x)                           # [B,128,1,T’]\n",
    "        x = x.squeeze(2).transpose(1,2)            # [B,T’,128]\n",
    "\n",
    "        # pack if lengths given (convert time to downsampled lengths)\n",
    "        if lengths is not None:\n",
    "            # two MaxPool(2,2) along time -> /4 in time\n",
    "            ds_lengths = (lengths.float() / 4.0).floor().clamp(min=1).long()\n",
    "            x_packed = nn.utils.rnn.pack_padded_sequence(x, ds_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            x_rnn, _ = self.rnn(x_packed)\n",
    "            x, _ = nn.utils.rnn.pad_packed_sequence(x_rnn, batch_first=True)\n",
    "        else:\n",
    "            x, _ = self.rnn(x)\n",
    "\n",
    "        if self.use_attention:\n",
    "            # simple attention over time\n",
    "            attn_w = self.attn(x).squeeze(-1)                 # [B,T’]\n",
    "            attn_w = torch.softmax(attn_w, dim=1)\n",
    "            out = torch.sum(x * attn_w.unsqueeze(-1), dim=1)  # [B, 2H]\n",
    "        else:\n",
    "            # mean pool over time\n",
    "            out = x.mean(dim=1)                                # [B, 2H]\n",
    "\n",
    "        logits = self.head(out)\n",
    "        return logits\n",
    "\n",
    "# Instantiate\n",
    "n_mels = int(train_df.iloc[0][\"n_mels\"])\n",
    "model = RCNN_Audio(n_mels=n_mels, n_classes=num_classes, rnn_hidden=128, rnn_layers=1, use_attention=False).to(device)\n",
    "sum(p.numel() for p in model.parameters())/1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORG 15\\AppData\\Local\\Temp\\ipykernel_33336\\750936264.py:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(USE_MIXED_PREC and device.type==\"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "# === Train / Validate ===\n",
    "class SmoothCELoss(nn.Module):\n",
    "    def __init__(self, label_smoothing=0.0, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.ls = float(label_smoothing)\n",
    "        self.register_buffer(\"w\", None if class_weights is None else torch.tensor(class_weights, dtype=torch.float32))\n",
    "    def forward(self, logits, target):\n",
    "        if self.ls > 0:\n",
    "            n = logits.size(-1)\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "            with torch.no_grad():\n",
    "                true_dist = torch.zeros_like(log_probs)\n",
    "                true_dist.fill_(self.ls / (n - 1))\n",
    "                true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.ls)\n",
    "            if self.w is not None:\n",
    "                # apply class weights as per-target scaling\n",
    "                weight = self.w[target]\n",
    "                loss = -(true_dist * log_probs).sum(dim=1) * weight\n",
    "                return loss.mean()\n",
    "            else:\n",
    "                return -(true_dist * log_probs).sum(dim=1).mean()\n",
    "        else:\n",
    "            return F.cross_entropy(logits, target, weight=self.w)\n",
    "\n",
    "# class weights from train set\n",
    "train_counts = train_df[\"y\"].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)\n",
    "class_weights = (train_counts.sum() / (train_counts + 1e-6))\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "\n",
    "criterion = SmoothCELoss(label_smoothing=LABEL_SMOOTHING, class_weights=class_weights).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(USE_MIXED_PREC and device.type==\"cuda\"))\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    total, correct = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x, y, lengths, metas in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with torch.cuda.amp.autocast(enabled=(USE_MIXED_PREC and device.type==\"cuda\")):\n",
    "                logits = model(x, lengths=lengths)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        probs = torch.softmax(logits.detach(), dim=-1)\n",
    "        pred = probs.argmax(dim=-1)\n",
    "\n",
    "        total += x.size(0)\n",
    "        correct += (pred == y).sum().item()\n",
    "        y_true.extend(y.cpu().tolist())\n",
    "        y_pred .extend(pred.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / max(1, total)\n",
    "    acc = correct / max(1, total)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    return epoch_loss, acc, f1m, (y_true, y_pred)\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_path = WORK_DIR / f\"rcnn_baseline_win{WIN_S}s.pt\"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    tr_loss, tr_acc, tr_f1, _ = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc, va_f1, (vy, vp) = run_epoch(val_loader,   train=False)\n",
    "    scheduler.step()\n",
    "\n",
    "    if va_f1 > best_f1:\n",
    "        best_f1 = va_f1\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"labels_sorted\": labels_sorted,\n",
    "                    \"cfg\": {\"win_s\": WIN_S, \"n_mels\": n_mels}}, best_path)\n",
    "\n",
    "    print(f\"[{epoch:02d}/{NUM_EPOCHS}] \"\n",
    "          f\"train: loss={tr_loss:.4f} acc={tr_acc:.3f} f1={tr_f1:.3f} | \"\n",
    "          f\"val: loss={va_loss:.4f} acc={va_acc:.3f} f1={va_f1:.3f} | best_f1={best_f1:.3f}\")\n",
    "\n",
    "print(\"Saved best →\", best_path)\n",
    "print(classification_report(vy, vp, target_names=[id_to_label[i] for i in range(num_classes)], digits=3, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76b0331",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === Inference helpers ===\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_mel_npy\u001b[39m(model, npy_path):\n\u001b[0;32m      4\u001b[0m     mel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(npy_path)                      \u001b[38;5;66;03m# [n_mels, T]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mel)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# [1,1,n_mels,T]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# === Inference helpers ===\n",
    "@torch.no_grad()\n",
    "def predict_mel_npy(model, npy_path):\n",
    "    mel = np.load(npy_path)                      # [n_mels, T]\n",
    "    x = torch.from_numpy(mel).float().unsqueeze(0).unsqueeze(0).to(device)  # [1,1,n_mels,T]\n",
    "    logits = model(x, lengths=torch.tensor([mel.shape[1]])).softmax(dim=-1).squeeze(0).cpu().numpy()\n",
    "    pred_id = int(logits.argmax())\n",
    "    return pred_id, logits\n",
    "\n",
    "def load_best_model(path):\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    m = RCNN_Audio(n_mels=ckpt[\"cfg\"][\"n_mels\"], n_classes=len(ckpt[\"labels_sorted\"]),\n",
    "                   rnn_hidden=128, rnn_layers=1, use_attention=False).to(device)\n",
    "    m.load_state_dict(ckpt[\"model\"]); m.eval()\n",
    "    return m, ckpt[\"labels_sorted\"]\n",
    "\n",
    "# Example:\n",
    "# best_model, class_names = load_best_model(best_path)\n",
    "# test_row = val_df.sample(1, random_state=SEED).iloc[0]\n",
    "# pid, probs = predict_mel_npy(best_model, test_row[\"mel_npy\"])\n",
    "# print(\"GT:\", test_row[\"event_label\"], \"Pred:\", class_names[pid])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
